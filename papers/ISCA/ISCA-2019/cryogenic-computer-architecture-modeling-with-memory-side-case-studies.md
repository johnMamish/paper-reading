Dennard scaling has killed power reduction gains with mostfet scaling, and the memory wall has altered the growth of computer architecture. A proposed mitigation to both of these issues is "cryogenic computing", basically dunking traditional CPUs in liquid nitrogen. However, this changes architectural tradeoffs; transistors, interconnect, and memory behave substantially differently. To fully realize the performance gains, architects will have to re-evaluate these tradeoffs in the cryogenic domain.

The authors present a memory model for DRAM operating at 77K which they hope architects can use to design DRAM that's specifically optimized for that performance point. They validate their model with real-world hardware and in section 7 discuss the holistic feasibility of cooling DRAM to cryogenic temperatures (does DRAM performance REALLY improve so much? cooling DRAM that far is hard work).

Hot takes:
personal interest: 1/10
paper quality / novelty: 6/10