## Wireless Computer Vision Using Commodity Radios
#### [[Colleen Josephson]], Lei Yang, Pengyu Zhang, Sachin Katti, 2016

#### Summary
Wireless video streaming is desirable for a number of applications (security / surveillance (oh no), VR, environmental monitoring, etc), but because of video's high data rate, it usually requires a massive amount of energy to transmit frames. The authors develop a system which brings together many different techniques to drastically reduce the amount of power required for continuous operation in a traditional convert-compute-transmit wireless imaging system.

The authors optimize the following parts of the system:
 * The image sensor: the authors use an off-the-shelf solution with orders-of-magnitude lower power than other similar sensors.
 * The RF hardware (sections 3.2.1, 4.2.1): the authors use backscatter for both TX and RX on the camera board; the backscatter scheme uses packets generated by commodity WiFi hardware, where data bits are encoded in packet characteristics like packet length. On the camera, the authors implement the RX side with an envelope detector (LT5534) and implement the TX side with an FPGA and an RF switch.
 * The compression algorithm (section 3.2.3): the authors break the image into sub-blocks and monitor the variation of a sub-block, only transmitting sub-blocks whose pixel values change above a certain threshold; sub-block levels are captured periodically in FRAM. They organize the order-of-operations in this simple algorithm to make sure that FRAM writes are limited.
 * Adaptive framerate / resolution (section 3.1.3): The receiver (which is not energy-bound) uses an attention model (kind of like Microsoft's Glimpse) to command the camera to increase resolution when it thinks something interesting may be in the frame. In their example application, the camera is commanded to increase resolution when there may be a face, which increases power consumption briefly.

The system successfully transmits continuous 1fps video using 9.7mW when transmitting 164x122 images and 18.8mW when transmitting 326x244 images. When the system adaptively chooses between low- and high- res images, the average power consumption is 11.4mW. It uses entirely commodity hardware and outperforms similar systems, except possibly the "Towards HD" system, which uses some non-commodity hardware. I'm interested in seeing how a more sophisticated compression algorithm could advance this system, possibly aided by beyond-CMOS computing, e.g. MTJs.

#### Strengths
 * Actual hardware was built
 * System is built entirely from commodity hardware
 * System achieves state-of-the-art performance

#### Weaknesses
 * Lack of clarity about compression vs resolution in discussion

#### Additional comments
Because I'll be meeting Colleen in person soon, I'm interested in discussing a few things w her:
 * Working with the hm01b0:
   * How quickly can it be brought up from a cold start? How do you go about setting automatic exposure and 50/60Hz flicker cancellation settings at startup?
   * How did you get in touch with them about acquiring bare dies?
   * How do they achieve so much lower power? Do you know?
 * Compression techniques for the image: are there future directions she'd like to move in?
 * Some sort of compute-in-memory thing?
 * I have a future vision for 320x240 20-30FPS  image collection, compression, and storage in < 10mW. Thoughts?

Keywords: #keywords/camera #keywords/sensor #keywords/low-power #keywords/backscatter
Tags: 